# LunarLaurus MCP Server Environment Configuration
# Copy this file to .env and customize as needed

# Server Configuration
SERVER_PORT=8000

# GPU Backend (Ollama)
LLM_GPU_ENDPOINT=http://localhost:11434/api/generate
LLM_GPU_MODEL=mistral:7b-instruct

# CPU Backend (llama.cpp)
LLM_CPU_ENDPOINT=http://localhost:8080/completion
LLM_CPU_MODEL=mistral-7b-instruct-q4

# Embedding Service
EMBEDDING_ENDPOINT=http://localhost:11434/api/embeddings
EMBEDDING_MODEL=nomic-embed-text

# Spring Boot Configuration
SPRING_PROFILES_ACTIVE=production
LOGGING_LEVEL=INFO

# Routing Thresholds (in tokens)
GPU_MAX_TOKENS=2000
CPU_MAX_TOKENS=8000

# Optional: Cloud Fallback (if configured)
# CLOUD_API_ENDPOINT=https://api.anthropic.com/v1/messages
# CLOUD_API_KEY=your-api-key-here
